---
layout: post
title: 'Tutorial on Principal Components Analysis (PCA) and Singular Value Decomposition (SVD) using Python'
date: 2015-02-10 20:12:55.000000000 -08:00
categories: []
tags: []
status: draft
type: post
published: true
---
<p>Principal Components Analysis is useful as a dimensionality reduction method. I decided to write the example below here in Python, using a combination of gists and Jupyter notebooks. For simplicity, I will descrobe PCA in a few steps, like in a recipe:</p>
<h3>Recipe for PCA</h3>
<ul>
    <li>Calculate deviation matrix</li>
    <li>Calculate covariance matrix</li>
    <li>Calculate eigenvectors and eigenvalues of the covariance matrix</li>
    <li>Calculate loadings and scores</li>
</ul>
<p>How to roll PCA from scratch</p>
<p>Limitations/Assumptions about PCA</p>
<p>How SVD is better</p>
<p>SVD can be thought of as a generalization of PCA. When we use SVD, we actually don't obtain the principal components directly, but we can easily obtain them through a few operations. Here's the recipe:</p>
<ul>
    <li>Calculate deviation matrix</li>
    <li>Perform decomposition</li>
    <li>Square the diagonal matrix S, and divide by sum(S) to obtain eigenvalues</li>
    <li>Matrix Vt (or U) will contain the eigenvectors</li>
</ul>
<p>Translating from PCA to SVD</p>

